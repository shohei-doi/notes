<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">

<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1"/>
  <meta name="generator" content="distill" />

  <style type="text/css">
  /* Hide doc at startup (prevent jankiness while JS renders/transforms) */
  body {
    visibility: hidden;
  }
  </style>

 <!--radix_placeholder_import_source-->
 <!--/radix_placeholder_import_source-->

  <!--radix_placeholder_meta_tags-->
  <title>Rで機械学習：分類編</title>
  
  <meta property="description" itemprop="description" content="Rで機械学習による分類を行ういくつかの方法を説明します。"/>
  
  
  <!--  https://schema.org/Article -->
  <meta property="article:published" itemprop="datePublished" content="2019-05-27"/>
  <meta property="article:created" itemprop="dateCreated" content="2019-05-27"/>
  <meta name="article:author" content="土井　翔平"/>
  
  <!--  https://developers.facebook.com/docs/sharing/webmasters#markup -->
  <meta property="og:title" content="Rで機械学習：分類編"/>
  <meta property="og:type" content="article"/>
  <meta property="og:description" content="Rで機械学習による分類を行ういくつかの方法を説明します。"/>
  <meta property="og:locale" content="en_US"/>
  
  <!--  https://dev.twitter.com/cards/types/summary -->
  <meta property="twitter:card" content="summary"/>
  <meta property="twitter:title" content="Rで機械学習：分類編"/>
  <meta property="twitter:description" content="Rで機械学習による分類を行ういくつかの方法を説明します。"/>
  <meta property="twitter:creator" content="@sdoi0504"/>
  
  <!--/radix_placeholder_meta_tags-->
  <!--radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-rmarkdown-metadata">
  {"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["title","description","author","date","output","categories","twitter"]}},"value":[{"type":"character","attributes":{},"value":["Rで機械学習：分類編"]},{"type":"character","attributes":{},"value":["Rで機械学習による分類を行ういくつかの方法を説明します。\n"]},{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","affiliation"]}},"value":[{"type":"character","attributes":{},"value":["土井　翔平"]},{"type":"character","attributes":{},"value":["国立情報学研究所"]}]}]},{"type":"character","attributes":{},"value":["2019-05-27"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["distill::distill_article"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["self_contained","toc","toc_depth"]}},"value":[{"type":"logical","attributes":{},"value":[false]},{"type":"logical","attributes":{},"value":[true]},{"type":"integer","attributes":{},"value":[2]}]}]},{"type":"character","attributes":{},"value":["R","data analysis"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["creator"]}},"value":[{"type":"character","attributes":{},"value":["@sdoi0504"]}]}]}
  </script>
  <!--/radix_placeholder_rmarkdown_metadata-->
  
  <script type="text/json" id="radix-resource-manifest">
  {"type":"character","attributes":{},"value":["classification_files/bowser-1.9.3/bowser.min.js","classification_files/distill-2.2.21/template.v2.js","classification_files/jquery-1.11.3/jquery.min.js","classification_files/webcomponents-2.0.0/webcomponents.js"]}
  </script>
  <!--radix_placeholder_navigation_in_header-->
  <!--/radix_placeholder_navigation_in_header-->
  <!--radix_placeholder_distill-->
  
  <style type="text/css">
  
  body {
    background-color: white;
  }
  
  .pandoc-table {
    width: 100%;
  }
  
  .pandoc-table>caption {
    margin-bottom: 10px;
  }
  
  .pandoc-table th:not([align]) {
    text-align: left;
  }
  
  .pagedtable-footer {
    font-size: 15px;
  }
  
  .html-widget {
    margin-bottom: 2.0em;
  }
  
  .l-screen-inset {
    padding-right: 16px;
  }
  
  .l-screen .caption {
    margin-left: 10px;
  }
  
  .shaded {
    background: rgb(247, 247, 247);
    padding-top: 20px;
    padding-bottom: 20px;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
    border-bottom: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .html-widget {
    margin-bottom: 0;
    border: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .shaded .shaded-content {
    background: white;
  }
  
  .text-output {
    margin-top: 0;
    line-height: 1.5em;
  }
  
  .hidden {
    display: none !important;
  }
  
  d-article {
    padding-bottom: 30px;
  }
  
  d-appendix {
    padding-top: 30px;
  }
  
  d-article>p>img {
    width: 100%;
  }
  
  d-article iframe {
    border: 1px solid rgba(0, 0, 0, 0.1);
    margin-bottom: 2.0em;
    width: 100%;
  }
  
  figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  /* CSS for table of contents */
  
  .d-toc {
    color: rgba(0,0,0,0.8);
    font-size: 0.8em;
    line-height: 1em;
  }
  
  .d-toc-header {
    font-size: 0.6rem;
    font-weight: 400;
    color: rgba(0, 0, 0, 0.5);
    text-transform: uppercase;
    margin-top: 0;
    margin-bottom: 1.3em;
  }
  
  .d-toc a {
    border-bottom: none;
  }
  
  .d-toc ul {
    padding-left: 0;
  }
  
  .d-toc li>ul {
    padding-top: 0.8em;
    padding-left: 16px;
    margin-bottom: 0.6em;
  }
  
  .d-toc ul,
  .d-toc li {
    list-style-type: none;
  }
  
  .d-toc li {
    margin-bottom: 0.9em;
  }
  
  .d-toc-separator {
    margin-top: 20px;
    margin-bottom: 2em;
  }
  
  .d-article-with-toc {
    border-top: none;
    padding-top: 0;
  }
  
  
  
  /* Tweak code blocks (note that this CSS is repeated above in an injection
     into the d-code shadow dom) */
  
  d-code {
    overflow-x: auto !important;
  }
  
  pre.d-code code.d-code {
    padding-left: 10px;
    font-size: 12px;
    border-left: 2px solid rgba(0,0,0,0.1);
  }
  
  pre.text-output {
  
    font-size: 12px;
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  @media(min-width: 768px) {
  
  d-code {
    overflow-x: visible !important;
  }
  
  pre.d-code code.d-code  {
      padding-left: 18px;
      font-size: 14px;
  }
  pre.text-output {
    font-size: 14px;
  }
  }
  
  /* Figure */
  
  .figure {
    position: relative;
    margin-bottom: 2.5em;
    margin-top: 1.5em;
  }
  
  .figure img {
    width: 100%;
  }
  
  .figure .caption {
    color: rgba(0, 0, 0, 0.6);
    font-size: 12px;
    line-height: 1.5em;
  }
  
  .figure img.external {
    background: white;
    border: 1px solid rgba(0, 0, 0, 0.1);
    box-shadow: 0 1px 8px rgba(0, 0, 0, 0.1);
    padding: 18px;
    box-sizing: border-box;
  }
  
  .figure .caption a {
    color: rgba(0, 0, 0, 0.6);
  }
  
  .figure .caption b,
  .figure .caption strong, {
    font-weight: 600;
    color: rgba(0, 0, 0, 1.0);
  }
  
  
  
  /* Tweak 1000px media break to show more text */
  
  @media(min-width: 1000px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 80px [middle-start] 50px [text-start kicker-end] 65px 65px 65px 65px 65px 65px 65px 65px [text-end gutter-start] 65px [middle-end] 65px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 16px;
    }
  
    .grid {
      grid-column-gap: 16px;
    }
  
    d-article {
      font-size: 1.06rem;
      line-height: 1.7em;
    }
    figure .caption, .figure .caption, figure figcaption {
      font-size: 13px;
    }
  }
  
  @media(min-width: 1180px) {
    .base-grid,
    distill-header,
    d-title,
    d-abstract,
    d-article,
    d-appendix,
    distill-appendix,
    d-byline,
    d-footnote-list,
    d-citation-list,
    distill-footer {
      grid-template-columns: [screen-start] 1fr [page-start kicker-start] 60px [middle-start] 60px [text-start kicker-end] 60px 60px 60px 60px 60px 60px 60px 60px [text-end gutter-start] 60px [middle-end] 60px [page-end gutter-end] 1fr [screen-end];
      grid-column-gap: 32px;
    }
  
    .grid {
      grid-column-gap: 32px;
    }
  }
  
  
  /* Get the citation styles for the appendix (not auto-injected on render since
     we do our own rendering of the citation appendix) */
  
  d-appendix .citation-appendix,
  .d-appendix .citation-appendix {
    font-size: 11px;
    line-height: 15px;
    border-left: 1px solid rgba(0, 0, 0, 0.1);
    padding-left: 18px;
    border: 1px solid rgba(0,0,0,0.1);
    background: rgba(0, 0, 0, 0.02);
    padding: 10px 18px;
    border-radius: 3px;
    color: rgba(150, 150, 150, 1);
    overflow: hidden;
    margin-top: -12px;
    white-space: pre-wrap;
    word-wrap: break-word;
  }
  
  
  /* Social footer */
  
  .social_footer {
    margin-top: 30px;
    margin-bottom: 0;
    color: rgba(0,0,0,0.67);
  }
  
  .disqus-comments {
    margin-right: 30px;
  }
  
  .disqus-comment-count {
    border-bottom: 1px solid rgba(0, 0, 0, 0.4);
    cursor: pointer;
  }
  
  #disqus_thread {
    margin-top: 30px;
  }
  
  .article-sharing a {
    border-bottom: none;
    margin-right: 8px;
  }
  
  .article-sharing a:hover {
    border-bottom: none;
  }
  
  .sidebar-section.subscribe {
    font-size: 12px;
    line-height: 1.6em;
  }
  
  .subscribe p {
    margin-bottom: 0.5em;
  }
  
  
  .article-footer .subscribe {
    font-size: 15px;
    margin-top: 45px;
  }
  
  
  /* Improve display for browsers without grid (IE/Edge <= 15) */
  
  .downlevel {
    line-height: 1.6em;
    font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Fira Sans", "Droid Sans", "Helvetica Neue", Arial, sans-serif;
    margin: 0;
  }
  
  .downlevel .d-title {
    padding-top: 6rem;
    padding-bottom: 1.5rem;
  }
  
  .downlevel .d-title h1 {
    font-size: 50px;
    font-weight: 700;
    line-height: 1.1em;
    margin: 0 0 0.5rem;
  }
  
  .downlevel .d-title p {
    font-weight: 300;
    font-size: 1.2rem;
    line-height: 1.55em;
    margin-top: 0;
  }
  
  .downlevel .d-byline {
    padding-top: 0.8em;
    padding-bottom: 0.8em;
    font-size: 0.8rem;
    line-height: 1.8em;
  }
  
  .downlevel .section-separator {
    border: none;
    border-top: 1px solid rgba(0, 0, 0, 0.1);
  }
  
  .downlevel .d-article {
    font-size: 1.06rem;
    line-height: 1.7em;
    padding-top: 1rem;
    padding-bottom: 2rem;
  }
  
  
  .downlevel .d-appendix {
    padding-left: 0;
    padding-right: 0;
    max-width: none;
    font-size: 0.8em;
    line-height: 1.7em;
    margin-bottom: 0;
    color: rgba(0,0,0,0.5);
    padding-top: 40px;
    padding-bottom: 48px;
  }
  
  .downlevel .footnotes ol {
    padding-left: 13px;
  }
  
  .downlevel .base-grid,
  .downlevel .distill-header,
  .downlevel .d-title,
  .downlevel .d-abstract,
  .downlevel .d-article,
  .downlevel .d-appendix,
  .downlevel .distill-appendix,
  .downlevel .d-byline,
  .downlevel .d-footnote-list,
  .downlevel .d-citation-list,
  .downlevel .distill-footer,
  .downlevel .appendix-bottom,
  .downlevel .posts-container {
    padding-left: 40px;
    padding-right: 40px;
  }
  
  @media(min-width: 768px) {
    .downlevel .base-grid,
    .downlevel .distill-header,
    .downlevel .d-title,
    .downlevel .d-abstract,
    .downlevel .d-article,
    .downlevel .d-appendix,
    .downlevel .distill-appendix,
    .downlevel .d-byline,
    .downlevel .d-footnote-list,
    .downlevel .d-citation-list,
    .downlevel .distill-footer,
    .downlevel .appendix-bottom,
    .downlevel .posts-container {
    padding-left: 150px;
    padding-right: 150px;
    max-width: 900px;
  }
  }
  
  .downlevel pre code {
    display: block;
    border-left: 2px solid rgba(0, 0, 0, .1);
    padding: 0 0 0 20px;
    font-size: 14px;
  }
  
  .downlevel code, .downlevel pre {
    color: black;
    background: none;
    font-family: Consolas, Monaco, 'Andale Mono', 'Ubuntu Mono', monospace;
    text-align: left;
    white-space: pre;
    word-spacing: normal;
    word-break: normal;
    word-wrap: normal;
    line-height: 1.5;
  
    -moz-tab-size: 4;
    -o-tab-size: 4;
    tab-size: 4;
  
    -webkit-hyphens: none;
    -moz-hyphens: none;
    -ms-hyphens: none;
    hyphens: none;
  }
  
  </style>
  
  <script type="application/javascript">
  
  function is_downlevel_browser() {
    if (bowser.isUnsupportedBrowser({ msie: "12", msedge: "16"},
                                   window.navigator.userAgent)) {
      return true;
    } else {
      return window.load_distill_framework === undefined;
    }
  }
  
  // show body when load is complete
  function on_load_complete() {
  
    // set body to visible
    document.body.style.visibility = 'visible';
  
    // force redraw for leaflet widgets
    if (window.HTMLWidgets) {
      var maps = window.HTMLWidgets.findAll(".leaflet");
      $.each(maps, function(i, el) {
        var map = this.getMap();
        map.invalidateSize();
        map.eachLayer(function(layer) {
          if (layer instanceof L.TileLayer)
            layer.redraw();
        });
      });
    }
  
    // trigger 'shown' so htmlwidgets resize
    $('d-article').trigger('shown');
  }
  
  function init_distill() {
  
    init_common();
  
    // create front matter
    var front_matter = $('<d-front-matter></d-front-matter>');
    $('#distill-front-matter').wrap(front_matter);
  
    // create d-title
    $('.d-title').changeElementType('d-title');
  
    // create d-byline
    var byline = $('<d-byline></d-byline>');
    $('.d-byline').replaceWith(byline);
  
    // create d-article
    var article = $('<d-article></d-article>');
    $('.d-article').wrap(article).children().unwrap();
  
    // move posts container into article
    $('.posts-container').appendTo($('d-article'));
  
    // create d-appendix
    $('.d-appendix').changeElementType('d-appendix');
  
    // create d-bibliography
    var bibliography = $('<d-bibliography></d-bibliography>');
    $('#distill-bibliography').wrap(bibliography);
  
    // flag indicating that we have appendix items
    var appendix = $('.appendix-bottom').children('h3').length > 0;
  
    // replace citations with <d-cite>
    $('.citation').each(function(i, val) {
      appendix = true;
      var cites = $(this).attr('data-cites').split(" ");
      var dt_cite = $('<d-cite></d-cite>');
      dt_cite.attr('key', cites.join());
      $(this).replaceWith(dt_cite);
    });
    // remove refs
    $('#refs').remove();
  
    // replace footnotes with <d-footnote>
    $('.footnote-ref').each(function(i, val) {
      appendix = true;
      var href = $(this).attr('href');
      var id = href.replace('#', '');
      var fn = $('#' + id);
      var fn_p = $('#' + id + '>p');
      fn_p.find('.footnote-back').remove();
      var text = fn_p.html();
      var dtfn = $('<d-footnote></d-footnote>');
      dtfn.html(text);
      $(this).replaceWith(dtfn);
    });
    // remove footnotes
    $('.footnotes').remove();
  
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      var id = $(this).attr('id');
      $('.d-toc a[href="#' + id + '"]').parent().remove();
      appendix = true;
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('d-appendix'));
    });
  
    // show d-appendix if we have appendix content
    $("d-appendix").css('display', appendix ? 'grid' : 'none');
  
    // replace code blocks with d-code
    $('pre>code').each(function(i, val) {
      var code = $(this);
      var pre = code.parent();
      var clz = "";
      var language = pre.attr('class');
      if (language) {
        // map unknown languages to "clike" (without this they just dissapear)
        if ($.inArray(language, ["bash", "clike", "css", "go", "html",
                                 "javascript", "js", "julia", "lua", "markdown",
                                 "markup", "mathml", "python", "svg", "xml"]) == -1)
          language = "clike";
        language = ' language="' + language + '"';
        var dt_code = $('<d-code block' + language + clz + '></d-code>');
        dt_code.text(code.text());
        pre.replaceWith(dt_code);
      } else {
        code.addClass('text-output').unwrap().changeElementType('pre');
      }
    });
  
    // localize layout chunks to just output
    $('.layout-chunk').each(function(i, val) {
  
      // capture layout
      var layout = $(this).attr('data-layout');
  
      // apply layout to markdown level block elements
      var elements = $(this).children().not('d-code, pre.text-output, script');
      elements.each(function(i, el) {
        var layout_div = $('<div class="' + layout + '"></div>');
        if (layout_div.hasClass('shaded')) {
          var shaded_content = $('<div class="shaded-content"></div>');
          $(this).wrap(shaded_content);
          $(this).parent().wrap(layout_div);
        } else {
          $(this).wrap(layout_div);
        }
      });
  
  
      // unwrap the layout-chunk div
      $(this).children().unwrap();
    });
  
    // load distill framework
    load_distill_framework();
  
    // wait for window.distillRunlevel == 4 to do post processing
    function distill_post_process() {
  
      if (!window.distillRunlevel || window.distillRunlevel < 4)
        return;
  
      // hide author/affiliations entirely if we have no authors
      var front_matter = JSON.parse($("#distill-front-matter").html());
      var have_authors = front_matter.authors && front_matter.authors.length > 0;
      if (!have_authors)
        $('d-byline').addClass('hidden');
  
      // table of contents
      if (have_authors) // adjust border if we are in authors
        $('.d-toc').parent().addClass('d-article-with-toc');
  
      // strip links that point to #
      $('.authors-affiliations').find('a[href="#"]').removeAttr('href');
  
      // hide elements of author/affiliations grid that have no value
      function hide_byline_column(caption) {
        $('d-byline').find('h3:contains("' + caption + '")').parent().css('visibility', 'hidden');
      }
  
      // affiliations
      var have_affiliations = false;
      for (var i = 0; i<front_matter.authors.length; ++i) {
        var author = front_matter.authors[i];
        if (author.affiliation !== "&nbsp;") {
          have_affiliations = true;
          break;
        }
      }
      if (!have_affiliations)
        $('d-byline').find('h3:contains("Affiliations")').css('visibility', 'hidden');
  
      // published date
      if (!front_matter.publishedDate)
        hide_byline_column("Published");
  
      // document object identifier
      var doi = $('d-byline').find('h3:contains("DOI")');
      var doi_p = doi.next().empty();
      if (!front_matter.doi) {
        // if we have a citation and valid citationText then link to that
        if ($('#citation').length > 0 && front_matter.citationText) {
          doi.html('Citation');
          $('<a href="#citation"></a>')
            .text(front_matter.citationText)
            .appendTo(doi_p);
        } else {
          hide_byline_column("DOI");
        }
      } else {
        $('<a></a>')
           .attr('href', "https://doi.org/" + front_matter.doi)
           .html(front_matter.doi)
           .appendTo(doi_p);
      }
  
       // change plural form of authors/affiliations
      if (front_matter.authors.length === 1) {
        var grid = $('.authors-affiliations');
        grid.children('h3:contains("Authors")').text('Author');
        grid.children('h3:contains("Affiliations")').text('Affiliation');
      }
  
      // inject pre code styles (can't do this with a global stylesheet b/c a shadow root is used)
      $('d-code').each(function(i, val) {
        var style = document.createElement('style');
        style.innerHTML = 'pre code { padding-left: 10px; font-size: 12px; border-left: 2px solid rgba(0,0,0,0.1); } ' +
                          '@media(min-width: 768px) { pre code { padding-left: 18px; font-size: 14px; } }';
        if (this.shadowRoot)
          this.shadowRoot.appendChild(style);
      });
  
      // move appendix-bottom entries to the bottom
      $('.appendix-bottom').appendTo('d-appendix').children().unwrap();
      $('.appendix-bottom').remove();
  
      // clear polling timer
      clearInterval(tid);
  
      // show body now that everything is ready
      on_load_complete();
    }
  
    var tid = setInterval(distill_post_process, 50);
    distill_post_process();
  
  }
  
  function init_downlevel() {
  
    init_common();
  
     // insert hr after d-title
    $('.d-title').after($('<hr class="section-separator"/>'));
  
    // check if we have authors
    var front_matter = JSON.parse($("#distill-front-matter").html());
    var have_authors = front_matter.authors && front_matter.authors.length > 0;
  
    // manage byline/border
    if (!have_authors)
      $('.d-byline').remove();
    $('.d-byline').after($('<hr class="section-separator"/>'));
    $('.d-byline a').remove();
  
    // remove toc
    $('.d-toc-header').remove();
    $('.d-toc').remove();
    $('.d-toc-separator').remove();
  
    // move appendix elements
    $('h1.appendix, h2.appendix').each(function(i, val) {
      $(this).changeElementType('h3');
    });
    $('h3.appendix').each(function(i, val) {
      $(this).nextUntil($('h1, h2, h3')).addBack().appendTo($('.d-appendix'));
    });
  
  
    // inject headers into references and footnotes
    var refs_header = $('<h3></h3>');
    refs_header.text('References');
    $('#refs').prepend(refs_header);
  
    var footnotes_header = $('<h3></h3');
    footnotes_header.text('Footnotes');
    $('.footnotes').children('hr').first().replaceWith(footnotes_header);
  
    // move appendix-bottom entries to the bottom
    $('.appendix-bottom').appendTo('.d-appendix').children().unwrap();
    $('.appendix-bottom').remove();
  
    // remove appendix if it's empty
    if ($('.d-appendix').children().length === 0)
      $('.d-appendix').remove();
  
    // prepend separator above appendix
    $('.d-appendix').before($('<hr class="section-separator" style="clear: both"/>'));
  
    // trim code
    $('pre>code').each(function(i, val) {
      $(this).html($.trim($(this).html()));
    });
  
    // move posts-container right before article
    $('.posts-container').insertBefore($('.d-article'));
  
    $('body').addClass('downlevel');
  
    on_load_complete();
  }
  
  
  function init_common() {
  
    // jquery plugin to change element types
    (function($) {
      $.fn.changeElementType = function(newType) {
        var attrs = {};
  
        $.each(this[0].attributes, function(idx, attr) {
          attrs[attr.nodeName] = attr.nodeValue;
        });
  
        this.replaceWith(function() {
          return $("<" + newType + "/>", attrs).append($(this).contents());
        });
      };
    })(jQuery);
  
    // prevent underline for linked images
    $('a > img').parent().css({'border-bottom' : 'none'});
  
    // mark non-body figures created by knitr chunks as 100% width
    $('.layout-chunk').each(function(i, val) {
      var figures = $(this).find('img, .html-widget');
      if ($(this).attr('data-layout') !== "l-body") {
        figures.css('width', '100%');
      } else {
        figures.css('max-width', '100%');
        figures.filter("[width]").each(function(i, val) {
          var fig = $(this);
          fig.css('width', fig.attr('width') + 'px');
        });
  
      }
    });
  
    // auto-append index.html to post-preview links in file: protocol
    // and in rstudio ide preview
    $('.post-preview').each(function(i, val) {
      if (window.location.protocol === "file:")
        $(this).attr('href', $(this).attr('href') + "index.html");
    });
  
    // get rid of index.html references in header
    if (window.location.protocol !== "file:") {
      $('.distill-site-header a[href]').each(function(i,val) {
        $(this).attr('href', $(this).attr('href').replace("index.html", "./"));
      });
    }
  
    // add class to pandoc style tables
    $('tr.header').parent('thead').parent('table').addClass('pandoc-table');
    $('.kable-table').children('table').addClass('pandoc-table');
  
    // add figcaption style to table captions
    $('caption').parent('table').addClass("figcaption");
  
    // initialize posts list
    if (window.init_posts_list)
      window.init_posts_list();
  
    // implmement disqus comment link
    $('.disqus-comment-count').click(function() {
      window.headroom_prevent_pin = true;
      $('#disqus_thread').toggleClass('hidden');
      if (!$('#disqus_thread').hasClass('hidden')) {
        var offset = $(this).offset();
        $(window).resize();
        $('html, body').animate({
          scrollTop: offset.top - 35
        });
      }
    });
  }
  
  document.addEventListener('DOMContentLoaded', function() {
    if (is_downlevel_browser())
      init_downlevel();
    else
      window.addEventListener('WebComponentsReady', init_distill);
  });
  
  </script>
  
  <!--/radix_placeholder_distill-->
  <script src="classification_files/jquery-1.11.3/jquery.min.js"></script>
  <script src="classification_files/bowser-1.9.3/bowser.min.js"></script>
  <script src="classification_files/webcomponents-2.0.0/webcomponents.js"></script>
  <script src="classification_files/distill-2.2.21/template.v2.js"></script>
  <!--radix_placeholder_site_in_header-->
  <!--/radix_placeholder_site_in_header-->


</head>

<body>

<!--radix_placeholder_front_matter-->

<script id="distill-front-matter" type="text/json">
{"title":"Rで機械学習：分類編","description":"Rで機械学習による分類を行ういくつかの方法を説明します。","authors":[{"author":"土井　翔平","authorURL":"#","affiliation":"国立情報学研究所","affiliationURL":"#"}],"publishedDate":"2019-05-27T00:00:00.000+09:00","citationText":"翔平, 2019"}
</script>

<!--/radix_placeholder_front_matter-->
<!--radix_placeholder_navigation_before_body-->
<!--/radix_placeholder_navigation_before_body-->
<!--radix_placeholder_site_before_body-->
<!--/radix_placeholder_site_before_body-->

<div class="d-title">
<h1>Rで機械学習：分類編</h1>
<p>Rで機械学習による分類を行ういくつかの方法を説明します。</p>
</div>

<div class="d-byline">
  土井　翔平  (国立情報学研究所)
  
<br/>2019-05-27
</div>

<div class="d-article">
<h3 class="d-toc-header">Table of Contents</h3>
<nav class="d-toc" id="TOC">
<ul>
<li><a href="#Intro">はじめに</a></li>
<li><a href="#Logit">ロジスティック回帰</a></li>
<li><a href="#DecisionTree">決定木</a></li>
<li><a href="#RandomForest">ランダムフォレスト</a></li>
<li><a href="#SVM">SVM</a></li>
<li><a href="#NNet">ニューラルネット</a></li>
</ul>
</nav>
<hr class="d-toc-separator"/>
<h2 id="Intro">はじめに</h2>
<p>機械学習の分野では<a href="https://shohei-doi.github.io/notes/posts/2019-05-19-logistic/">（多項）ロジット</a>のように、クラスを予測することを分類(classification)と呼びます。 一方で、<a href="https://shohei-doi.github.io/notes/posts/2019-05-17-regression/">最小二乗法</a>のように連続値を予測することを回帰(regression)と呼びます。</p>
<p>今回は代表的な機械学習の分類手法である</p>
<ol type="1">
<li>ロジスティック回帰</li>
<li>決定木</li>
<li>ランダムフォレスト</li>
<li>サポート・ベクター・マシン (SVM)</li>
<li>ニューラルネット</li>
</ol>
<p>について、Rで行う方法を紹介します。</p>
<ul>
<li>実は回帰を行うときもほとんどやることは変わりません。</li>
</ul>
<h3>必要なパッケージの読み込み</h3>
<p>Rで機械学習を行う便利なパッケージとして<code>caret</code>と<code>mlr</code>があります（らしいです）。 今回は<code>caret</code>を使ってみます。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
library(tidyverse)</code></pre>
<pre><code>
Registered S3 methods overwritten by &#39;ggplot2&#39;:
  method         from 
  [.quosures     rlang
  c.quosures     rlang
  print.quosures rlang</code></pre>
<pre><code>
Registered S3 method overwritten by &#39;rvest&#39;:
  method            from
  read_xml.response xml2</code></pre>
<pre><code>
── Attaching packages ──────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse 1.2.1 ──</code></pre>
<pre><code>
✔ ggplot2 3.1.1       ✔ purrr   0.3.2  
✔ tibble  2.1.1       ✔ dplyr   0.8.0.1
✔ tidyr   0.8.3       ✔ stringr 1.4.0  
✔ readr   1.3.1       ✔ forcats 0.4.0  </code></pre>
<pre><code>
── Conflicts ─────────────────────────────────────────────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::filter() masks stats::filter()
✖ dplyr::lag()    masks stats::lag()</code></pre>
<pre class="r"><code>
library(caret)</code></pre>
<pre><code>
Loading required package: lattice</code></pre>
<pre><code>
Attaching package: &#39;caret&#39;</code></pre>
<pre><code>
The following object is masked from &#39;package:purrr&#39;:

    lift</code></pre>
</div>
<h3>必要なデータの読み込み</h3>
<p>例のごとく、<a href="http://www.masaki.j.u-tokyo.ac.jp/utas/utasv.html">東大・朝日共同調査</a>の2014年衆院選・2016年参院選世論調査のデータを使います。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
data &lt;- read_csv(&quot;http://www.masaki.j.u-tokyo.ac.jp/utas/2014_2016UTASV20161004.csv&quot;, 
                 locale = locale(encoding = &quot;shift-jis&quot;), na = c(&quot;66&quot;, &quot;99&quot;, &quot;999&quot;))</code></pre>
<pre><code>
Parsed with column specification:
cols(
  .default = col_character(),
  ID = col_double(),
  PREFEC = col_double(),
  HRDIST = col_double(),
  W1Q1 = col_double(),
  W1Q2 = col_double(),
  W1Q3 = col_double(),
  W1Q4 = col_double(),
  W1Q5_1 = col_double(),
  W1Q5_2 = col_double(),
  W1Q5_3 = col_double(),
  W1Q6 = col_double(),
  W1Q7 = col_double(),
  W1Q8 = col_double(),
  W1Q9 = col_double(),
  W1Q10 = col_double(),
  W1Q11 = col_double(),
  W1Q12 = col_double(),
  W1Q13 = col_double(),
  W1Q14_1 = col_double(),
  W1Q14_2_1 = col_double()
  # ... with 56 more columns
)</code></pre>
<pre><code>
See spec(...) for full column specifications.</code></pre>
<pre><code>
Warning: 8 parsing failures.
 row    col expected actual                                                                file
1810 PREFEC a double     -- &#39;http://www.masaki.j.u-tokyo.ac.jp/utas/2014_2016UTASV20161004.csv&#39;
1810 HRDIST a double     -- &#39;http://www.masaki.j.u-tokyo.ac.jp/utas/2014_2016UTASV20161004.csv&#39;
1811 PREFEC a double     -- &#39;http://www.masaki.j.u-tokyo.ac.jp/utas/2014_2016UTASV20161004.csv&#39;
1811 HRDIST a double     -- &#39;http://www.masaki.j.u-tokyo.ac.jp/utas/2014_2016UTASV20161004.csv&#39;
1812 PREFEC a double     -- &#39;http://www.masaki.j.u-tokyo.ac.jp/utas/2014_2016UTASV20161004.csv&#39;
.... ...... ........ ...... ...................................................................
See problems(...) for more details.</code></pre>
</div>
<ul>
<li>非該当は<code>66</code>で、無回答は<code>99</code>なので、これらを欠損値として読み込んでおきます。</li>
</ul>
<h3>下ごしらえ</h3>
<p>データセットの内、分析に使う変数を抜き出しておきます。 更に、数値ではなくカテゴリカルデータである</p>
<ul>
<li>投票に行ったかどうか</li>
<li>どの政党に投票したのか</li>
<li>性別</li>
<li>学歴</li>
<li>職業</li>
</ul>
<p>については<code>as.factor()</code>でカテゴリカルデータ（因子型）に変形しておきます。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
data &lt;- data %&gt;% 
  select(vote = W1Q1,
         party = W1Q2,
         sex = W1F1,
         age = W1F2,
         educ = W1F3,
         job = W1F4,
         W1Q7, W1Q8, W1Q9, W1Q10, W1Q11, W1Q12, W1Q13, W1Q14_1,
         W1Q16_1, W1Q16_2, W1Q16_3, W1Q16_4, W1Q16_5, W1Q16_6, 
         W1Q16_7, W1Q16_8, W1Q16_9, W1Q16_10, W1Q16_11, 
         W1Q16_12, W1Q16_13, W1Q16_14, W1Q16_15, W1Q16_16, W1Q16_17,
         W1Q19_1)%&gt;% 
  mutate(vote = vote - 1,
         vote = as.factor(vote),
         party = as.factor(party),
         sex = as.factor(sex),
         educ = as.factor(educ),
         job = as.factor(job))</code></pre>
</div>
<p>さらに、投票するかどうかを予測するデータセットと</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
data_vote &lt;- data %&gt;% 
  select(-party) %&gt;%
  rename(target = vote) %&gt;% 
  drop_na()</code></pre>
</div>
<p>投票先を予測するデータセットをそれぞれ分けておきます。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
data_party &lt;- data %&gt;% 
  select(-vote) %&gt;%
  rename(target = party) %&gt;% 
  drop_na()</code></pre>
</div>
<ul>
<li>まず、予測しない方の変数（投票するかどうかの場合は投票先、投票先の場合は投票するかどうか）を削除しておきます。</li>
<li>予測したい変数を<code>target</code>という名前に変えておきます。</li>
<li>欠損値のあるサンプルを<code>drop_na()</code>で削除しておきます。</li>
</ul>
<h3>シード値の設定</h3>
<p>いくつかの分析手法では乱数を用います。 その名の通り乱数は毎回違う値が出てくるので、分析結果も変わってきます。</p>
<p>そこで、乱数を発生させるときの基準となるシード値を設定することで、毎回同じ乱数が発生するようにします。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
set.seed(334)</code></pre>
</div>
<h3>機械学習の分類<code>*</code></h3>
<p>余談までに、機械学習全般の代表的な手法を概説します。</p>
<p>ちなみに、分類や回帰のように目的変数という正解が存在して、それを予測することを教師付き(supervised)学習と呼びます。 計量経済学や統計的因果推論は予測が主目的ではないですが、応答変数があるという意味で教師付き学習でと手法を共有しています。</p>
<p>逆に正解が存在せず、機械にデータから見えない構造を抽出させることを教師なし(unsupervised)学習と言います。 よくあるのはk-meansや混合ガウス分布(Gaussian mixture)、潜在ディリクレ配分(latent dirichlet allocation)によるクラスタリングです。</p>
<aside>
教師付きのclassificationを識別、教師なしのclusteringを分類と呼ぶ人もいます。 また、両者を合わせてパターン認識と呼ぶこともあります。
</aside>
<p>強化学習(reinforcement learning)とは正解は無いものの、目的は存在し、その目的を実現するための行動を学習するものです。 例えば、AlphaGo Zeroでは実際の棋譜を正解として使うのではなく、PC同士に何十日も戦わせて勝利という目的に近づく行動を学習しました。</p>
<h2 id="Logit">ロジスティック回帰</h2>
<p>ロジスティック回帰の方法は<a href="https://shohei-doi.github.io/notes/posts/2019-05-19-logistic/">以前</a>、解説をしましたが、比較のためにもう一度やります。</p>
<p><code>caret</code>では<code>train()</code>の中に<code>formula</code>、使用するデータ、分析手法を入力します。 まずは、年齢だけで予測してみます。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vote_logit &lt;- train(
  target ~ age,
  data = data_vote,
  method = &quot;glm&quot;,
  family = binomial()
)</code></pre>
</div>
<p>その後、<code>predict()</code>に分析したモデルと予測したいデータセットを入れて予測を行います。 予測結果と実際の値（今回は<code>target</code>）との比較を<code>confusionMatrix()</code>で行います。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
confusionMatrix(predict(vote_logit, data_vote), data_vote$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0    0    0
         1  389 1074
                                          
               Accuracy : 0.7341          
                 95% CI : (0.7107, 0.7566)
    No Information Rate : 0.7341          
    P-Value [Acc &gt; NIR] : 0.5136          
                                          
                  Kappa : 0               
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.0000          
            Specificity : 1.0000          
         Pos Pred Value :    NaN          
         Neg Pred Value : 0.7341          
             Prevalence : 0.2659          
         Detection Rate : 0.0000          
   Detection Prevalence : 0.0000          
      Balanced Accuracy : 0.5000          
                                          
       &#39;Positive&#39; Class : 0               
                                          </code></pre>
</div>
<p>いろいろ出てきますが、<code>Accuracy</code>を見ると72%ほどの予測精度があることが分かります。</p>
<aside>
前回と若干違うのは、回答に欠損があるサンプルを取り除いて、サンプルサイズが異なるからです。
</aside>
<p>多項ロジットもほぼ同様に行います。</p>
<ul>
<li><code>trace = FALSE</code>とすることで分析の経過を非表示にできます。</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
party_logit &lt;- train(
  target ~ age,
  data = data_party,
  method = &quot;multinom&quot;,
  trace = FALSE
)

confusionMatrix(predict(party_logit, data_party), data_party$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   1   2   3   4   5   6   7   8   9  90
        1  363 204 169 131  21 125  17  16   5  17
        2    0   0   0   0   0   0   0   0   0   0
        3    0   0   0   0   0   0   0   0   0   0
        4    0   0   0   0   0   0   0   0   0   0
        5    0   0   0   0   0   0   0   0   0   0
        6    0   0   0   0   0   0   0   0   0   0
        7    0   0   0   0   0   0   0   0   0   0
        8    0   0   0   0   0   0   0   0   0   0
        9    0   0   0   0   0   0   0   0   0   0
        90   0   0   0   0   0   0   0   0   0   0

Overall Statistics
                                          
               Accuracy : 0.3399          
                 95% CI : (0.3115, 0.3692)
    No Information Rate : 0.3399          
    P-Value [Acc &gt; NIR] : 0.5115          
                                          
                  Kappa : 0               
                                          
 Mcnemar&#39;s Test P-Value : NA              

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
Sensitivity            1.0000    0.000   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Specificity            0.0000    1.000   1.0000   1.0000  1.00000    1.000  1.00000  1.00000
Pos Pred Value         0.3399      NaN      NaN      NaN      NaN      NaN      NaN      NaN
Neg Pred Value            NaN    0.809   0.8418   0.8773  0.98034    0.883  0.98408  0.98502
Prevalence             0.3399    0.191   0.1582   0.1227  0.01966    0.117  0.01592  0.01498
Detection Rate         0.3399    0.000   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Detection Prevalence   1.0000    0.000   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Balanced Accuracy      0.5000    0.500   0.5000   0.5000  0.50000    0.500  0.50000  0.50000
                     Class: 9 Class: 90
Sensitivity          0.000000   0.00000
Specificity          1.000000   1.00000
Pos Pred Value            NaN       NaN
Neg Pred Value       0.995318   0.98408
Prevalence           0.004682   0.01592
Detection Rate       0.000000   0.00000
Detection Prevalence 0.000000   0.00000
Balanced Accuracy    0.500000   0.50000</code></pre>
</div>
<p>やはり、前回とほぼ同様の32%の予測精度があります。</p>
<h3>予測精度のからくり</h3>
<p>ところで、前回の記事で、これには「からくり」があると言いましたが、それは各分析結果の最初の表を見ると分かります。</p>
<p>表では縦軸に予測結果、横軸に実際の値があります。 それぞれのセルの中には該当するサンプルサイズが表示されています。 つまり、対角線上にある数が正解数を意味しています。</p>
<p>しかし、投票するかどうかでは全て<code>1</code>（＝投票に行く）と予測しており、投票先でも全て<code>1</code>（＝自民党に投票する）と予測しています。 そして、実際に投票に行った人が7割、自民党に投票した人が3割いるので、先程の予測精度になったということでした。</p>
<p>つまり、単純に正答率を予測精度として見る場合、その下限は0%ではないということです。</p>
<h3>特徴量を増やす</h3>
<p>予測精度を高めるシンプルな方法は特徴量を増やすことです。 年齢に加えて性別、学歴、職業、現状や政策に関する意見（問7から14,16(1)から(17)に対する答え）を入れて分析してみます。</p>
<ul>
<li><code>formula</code>の右辺を<code>.</code>とすることで「左辺の変数以外の全て」を意味します。</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vote_logit &lt;- train(
  target ~ .,
  data = data_vote,
  method = &quot;glm&quot;,
  family = binomial()
)

confusionMatrix(predict(vote_logit, data_vote), data_vote$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0  107   66
         1  282 1008
                                          
               Accuracy : 0.7621          
                 95% CI : (0.7395, 0.7837)
    No Information Rate : 0.7341          
    P-Value [Acc &gt; NIR] : 0.007762        
                                          
                  Kappa : 0.2596          
                                          
 Mcnemar&#39;s Test P-Value : &lt; 2.2e-16       
                                          
            Sensitivity : 0.27506         
            Specificity : 0.93855         
         Pos Pred Value : 0.61850         
         Neg Pred Value : 0.78140         
             Prevalence : 0.26589         
         Detection Rate : 0.07314         
   Detection Prevalence : 0.11825         
      Balanced Accuracy : 0.60681         
                                          
       &#39;Positive&#39; Class : 0               
                                          </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
party_logit &lt;- train(
  target ~ .,
  data = data_party,
  method = &quot;multinom&quot;,
  trace = FALSE
)

confusionMatrix(predict(party_logit, data_party), data_party$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   1   2   3   4   5   6   7   8   9  90
        1  309  42  55  79  10  25   3   3   2   8
        2   14  95  39   8   1  40  10   9   1   1
        3   21  24  50   8   0  12   3   0   0   1
        4   13  11   9  30   0   2   0   0   0   1
        5    0   0   0   0   9   0   0   0   0   0
        6    6  30  16   6   1  45   1   3   0   3
        7    0   2   0   0   0   0   0   0   0   0
        8    0   0   0   0   0   0   0   1   0   0
        9    0   0   0   0   0   0   0   0   2   0
        90   0   0   0   0   0   1   0   0   0   3

Overall Statistics
                                          
               Accuracy : 0.5094          
                 95% CI : (0.4789, 0.5398)
    No Information Rate : 0.3399          
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
                                          
                  Kappa : 0.3482          
                                          
 Mcnemar&#39;s Test P-Value : NA              

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7  Class: 8
Sensitivity            0.8512  0.46569  0.29586  0.22901 0.428571  0.36000 0.000000 0.0625000
Specificity            0.6780  0.85764  0.92325  0.96158 1.000000  0.93001 0.998097 1.0000000
Pos Pred Value         0.5765  0.43578  0.42017  0.45455 1.000000  0.40541 0.000000 1.0000000
Neg Pred Value         0.8985  0.87176  0.87460  0.89920 0.988669  0.91641 0.984053 0.9859419
Prevalence             0.3399  0.19101  0.15824  0.12266 0.019663  0.11704 0.015918 0.0149813
Detection Rate         0.2893  0.08895  0.04682  0.02809 0.008427  0.04213 0.000000 0.0009363
Detection Prevalence   0.5019  0.20412  0.11142  0.06180 0.008427  0.10393 0.001873 0.0009363
Balanced Accuracy      0.7646  0.66166  0.60955  0.59529 0.714286  0.64501 0.499049 0.5312500
                     Class: 9 Class: 90
Sensitivity          0.400000  0.176471
Specificity          1.000000  0.999049
Pos Pred Value       1.000000  0.750000
Neg Pred Value       0.997186  0.986842
Prevalence           0.004682  0.015918
Detection Rate       0.001873  0.002809
Detection Prevalence 0.001873  0.003745
Balanced Accuracy    0.700000  0.587760</code></pre>
</div>
<p>投票行動については若干の、投票先については大幅な改善が見られました。</p>
<h2 id="DecisionTree">決定木</h2>
<p>もう一つのアプローチは分析手法を変えることです。 <code>caret</code>の便利な点は様々な分類器をまとめて利用することができる点です。</p>
<aside>
機械学習では分類をするモデルを分類器(classifier)と呼ぶことがあります。
</aside>
<ul>
<li>しかし、<code>caret</code>自体にアルゴリズムは入っていないので、適宜、必要なパッケージをインストールするように促されます。</li>
</ul>
<p>まずは、シンプルな分類器である決定木(decision tree)について見てみます。 決定木とは以下の図（Wikipediaの<a href="https://ja.wikipedia.org/wiki/%E6%B1%BA%E5%AE%9A%E6%9C%A8">決定木のページ</a>より）のような決定木を作成します。 それぞれのノードでは変数の値によって分岐し、効率的に目的変数を分類していくことが目的です。</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/ja/5/5d/Decision_tree_model_ja.png" alt="決定木" /><figcaption>決定木</figcaption>
</figure>
<p><code>caret</code>では以下のように行います。</p>
<ul>
<li><code>rpart</code>とは決定木を求める方法の種類の一つ（らしい）です。</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vote_tree &lt;- train(
  target ~ .,
  data = data_vote,
  method = &quot;rpart&quot;
)

confusionMatrix(predict(vote_tree, data_vote), data_vote$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0    0    0
         1  389 1074
                                          
               Accuracy : 0.7341          
                 95% CI : (0.7107, 0.7566)
    No Information Rate : 0.7341          
    P-Value [Acc &gt; NIR] : 0.5136          
                                          
                  Kappa : 0               
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.0000          
            Specificity : 1.0000          
         Pos Pred Value :    NaN          
         Neg Pred Value : 0.7341          
             Prevalence : 0.2659          
         Detection Rate : 0.0000          
   Detection Prevalence : 0.0000          
      Balanced Accuracy : 0.5000          
                                          
       &#39;Positive&#39; Class : 0               
                                          </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
party_tree &lt;- train(
  target ~ .,
  data = data_party,
  method = &quot;rpart&quot;
)

confusionMatrix(predict(party_tree, data_party), data_party$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   1   2   3   4   5   6   7   8   9  90
        1  313  65  98 100  19  36   6   2   5   8
        2   50 139  71  31   2  89  11  14   0   9
        3    0   0   0   0   0   0   0   0   0   0
        4    0   0   0   0   0   0   0   0   0   0
        5    0   0   0   0   0   0   0   0   0   0
        6    0   0   0   0   0   0   0   0   0   0
        7    0   0   0   0   0   0   0   0   0   0
        8    0   0   0   0   0   0   0   0   0   0
        9    0   0   0   0   0   0   0   0   0   0
        90   0   0   0   0   0   0   0   0   0   0

Overall Statistics
                                          
               Accuracy : 0.4232          
                 95% CI : (0.3934, 0.4535)
    No Information Rate : 0.3399          
    P-Value [Acc &gt; NIR] : 9.235e-09       
                                          
                  Kappa : 0.1968          
                                          
 Mcnemar&#39;s Test P-Value : NA              

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
Sensitivity            0.8623   0.6814   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Specificity            0.5191   0.6794   1.0000   1.0000  1.00000    1.000  1.00000  1.00000
Pos Pred Value         0.4801   0.3341      NaN      NaN      NaN      NaN      NaN      NaN
Neg Pred Value         0.8798   0.9003   0.8418   0.8773  0.98034    0.883  0.98408  0.98502
Prevalence             0.3399   0.1910   0.1582   0.1227  0.01966    0.117  0.01592  0.01498
Detection Rate         0.2931   0.1301   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Detection Prevalence   0.6105   0.3895   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Balanced Accuracy      0.6907   0.6804   0.5000   0.5000  0.50000    0.500  0.50000  0.50000
                     Class: 9 Class: 90
Sensitivity          0.000000   0.00000
Specificity          1.000000   1.00000
Pos Pred Value            NaN       NaN
Neg Pred Value       0.995318   0.98408
Prevalence           0.004682   0.01592
Detection Rate       0.000000   0.00000
Detection Prevalence 0.000000   0.00000
Balanced Accuracy    0.500000   0.50000</code></pre>
</div>
<p>どちらもロジットよりも精度は高くないようです。</p>
<h2 id="RandomForest">ランダムフォレスト</h2>
<p>ランダムフォレストとは決定木を複数作り（つまり、森を作り）、その多数決で最終的な予測を行う分類器です。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vote_rf &lt;- train(
  target ~ .,
  data = data_vote,
  method = &quot;rf&quot;
)

confusionMatrix(predict(vote_rf, data_vote), data_vote$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0  385    0
         1    4 1074
                                         
               Accuracy : 0.9973         
                 95% CI : (0.993, 0.9993)
    No Information Rate : 0.7341         
    P-Value [Acc &gt; NIR] : &lt;2e-16         
                                         
                  Kappa : 0.993          
                                         
 Mcnemar&#39;s Test P-Value : 0.1336         
                                         
            Sensitivity : 0.9897         
            Specificity : 1.0000         
         Pos Pred Value : 1.0000         
         Neg Pred Value : 0.9963         
             Prevalence : 0.2659         
         Detection Rate : 0.2632         
   Detection Prevalence : 0.2632         
      Balanced Accuracy : 0.9949         
                                         
       &#39;Positive&#39; Class : 0              
                                         </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
party_rf &lt;- train(
  target ~ .,
  data = data_party,
  method = &quot;rf&quot;
)

confusionMatrix(predict(party_rf, data_party), data_party$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   1   2   3   4   5   6   7   8   9  90
        1  363   0   0   0   0   0   0   0   0   0
        2    0 204   0   0   0   0   0   0   0   0
        3    0   0 169   0   0   0   0   0   0   0
        4    0   0   0 131   0   0   0   0   0   0
        5    0   0   0   0  21   0   0   0   0   0
        6    0   0   0   0   0 125   0   1   0   0
        7    0   0   0   0   0   0  17   0   0   0
        8    0   0   0   0   0   0   0  15   0   0
        9    0   0   0   0   0   0   0   0   5   0
        90   0   0   0   0   0   0   0   0   0  17

Overall Statistics
                                     
               Accuracy : 0.9991     
                 95% CI : (0.9948, 1)
    No Information Rate : 0.3399     
    P-Value [Acc &gt; NIR] : &lt; 2.2e-16  
                                     
                  Kappa : 0.9988     
                                     
 Mcnemar&#39;s Test P-Value : NA         

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
Sensitivity            1.0000    1.000   1.0000   1.0000  1.00000   1.0000  1.00000  0.93750
Specificity            1.0000    1.000   1.0000   1.0000  1.00000   0.9989  1.00000  1.00000
Pos Pred Value         1.0000    1.000   1.0000   1.0000  1.00000   0.9921  1.00000  1.00000
Neg Pred Value         1.0000    1.000   1.0000   1.0000  1.00000   1.0000  1.00000  0.99905
Prevalence             0.3399    0.191   0.1582   0.1227  0.01966   0.1170  0.01592  0.01498
Detection Rate         0.3399    0.191   0.1582   0.1227  0.01966   0.1170  0.01592  0.01404
Detection Prevalence   0.3399    0.191   0.1582   0.1227  0.01966   0.1180  0.01592  0.01404
Balanced Accuracy      1.0000    1.000   1.0000   1.0000  1.00000   0.9995  1.00000  0.96875
                     Class: 9 Class: 90
Sensitivity          1.000000   1.00000
Specificity          1.000000   1.00000
Pos Pred Value       1.000000   1.00000
Neg Pred Value       1.000000   1.00000
Prevalence           0.004682   0.01592
Detection Rate       0.004682   0.01592
Detection Prevalence 0.004682   0.01592
Balanced Accuracy    1.000000   1.00000</code></pre>
</div>
<p>無事、どちらも正答率がほぼ100%を実現することができました。 決定木を何本も生やしていくので、並列化を行わないとそこそこ時間がかかりますが、優秀な決定木のようです。</p>
<ul>
<li>ランダムフォレストを更に改良したXGBoostというのが有能らしいです。</li>
</ul>
<p>残念ながら、ここにもからくりはあるのですが、ひとまず今回は様々な分類器を紹介することを目的に次に進みます。</p>
<h2 id="SVM">SVM</h2>
<p>SVMも分類機の一つです。 再びWikipediaのS<a href="https://ja.wikipedia.org/wiki/%E3%82%B5%E3%83%9D%E3%83%BC%E3%83%88%E3%83%99%E3%82%AF%E3%82%BF%E3%83%BC%E3%83%9E%E3%82%B7%E3%83%B3">VMのページ</a>からの引用ですが、サポートベクターマシンとは右図のようにグループの間の境界線を見つける手法になります。</p>
<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Kernel_Machine.svg/1200px-Kernel_Machine.svg.png" alt="SVM" /><figcaption>SVM</figcaption>
</figure>
<p>これだけでは至ってシンプルなのですが、SVMが有能である所以は、カーネルトリックを使うことで、左図のように曲がった境界線も見つけることができる点にあります。</p>
<p>境界線を曲げるにはカーネル関数を選択する必要がありますが、ここでは（おそらく）一般的に使われているradial kernelを使います。</p>
<ul>
<li>tree-basedじゃない場合は変数を正規化しておいた方がいいと言われています。</li>
</ul>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vote_svm &lt;- train(
  target ~ .,
  data = data_vote,
  method = &quot;svmRadial&quot;,
  preProcess = c(&quot;center&quot;, &quot;scale&quot;)
)

confusionMatrix(predict(vote_svm, data_vote), data_vote$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction    0    1
         0   14    0
         1  375 1074
                                          
               Accuracy : 0.7437          
                 95% CI : (0.7205, 0.7659)
    No Information Rate : 0.7341          
    P-Value [Acc &gt; NIR] : 0.2127          
                                          
                  Kappa : 0.052           
                                          
 Mcnemar&#39;s Test P-Value : &lt;2e-16          
                                          
            Sensitivity : 0.035990        
            Specificity : 1.000000        
         Pos Pred Value : 1.000000        
         Neg Pred Value : 0.741201        
             Prevalence : 0.265892        
         Detection Rate : 0.009569        
   Detection Prevalence : 0.009569        
      Balanced Accuracy : 0.517995        
                                          
       &#39;Positive&#39; Class : 0               
                                          </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
party_svm &lt;- train(
  target ~ .,
  data = data_party,
  method = &quot;svmRadial&quot;,
  preProcess = c(&quot;center&quot;, &quot;scale&quot;)
)

confusionMatrix(predict(party_svm, data_party), data_party$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   1   2   3   4   5   6   7   8   9  90
        1  349  78 111 114  19  38   4   4   5  12
        2   13 122  49  15   2  86  10  12   0   4
        3    1   4   9   2   0   1   3   0   0   1
        4    0   0   0   0   0   0   0   0   0   0
        5    0   0   0   0   0   0   0   0   0   0
        6    0   0   0   0   0   0   0   0   0   0
        7    0   0   0   0   0   0   0   0   0   0
        8    0   0   0   0   0   0   0   0   0   0
        9    0   0   0   0   0   0   0   0   0   0
        90   0   0   0   0   0   0   0   0   0   0

Overall Statistics
                                          
               Accuracy : 0.4494          
                 95% CI : (0.4193, 0.4798)
    No Information Rate : 0.3399          
    P-Value [Acc &gt; NIR] : 8.263e-14       
                                          
                  Kappa : 0.2216          
                                          
 Mcnemar&#39;s Test P-Value : NA              

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
Sensitivity            0.9614   0.5980 0.053254   0.0000  0.00000    0.000  0.00000  0.00000
Specificity            0.4539   0.7789 0.986652   1.0000  1.00000    1.000  1.00000  1.00000
Pos Pred Value         0.4755   0.3898 0.428571      NaN      NaN      NaN      NaN      NaN
Neg Pred Value         0.9581   0.8914 0.847182   0.8773  0.98034    0.883  0.98408  0.98502
Prevalence             0.3399   0.1910 0.158240   0.1227  0.01966    0.117  0.01592  0.01498
Detection Rate         0.3268   0.1142 0.008427   0.0000  0.00000    0.000  0.00000  0.00000
Detection Prevalence   0.6873   0.2931 0.019663   0.0000  0.00000    0.000  0.00000  0.00000
Balanced Accuracy      0.7077   0.6885 0.519953   0.5000  0.50000    0.500  0.50000  0.50000
                     Class: 9 Class: 90
Sensitivity          0.000000   0.00000
Specificity          1.000000   1.00000
Pos Pred Value            NaN       NaN
Neg Pred Value       0.995318   0.98408
Prevalence           0.004682   0.01592
Detection Rate       0.000000   0.00000
Detection Prevalence 0.000000   0.00000
Balanced Accuracy    0.500000   0.50000</code></pre>
</div>
<p>残念ながら（？）、今回は決定木と同じくらいの性能しか出ませんでした。</p>
<h2 id="NNet">ニューラルネット</h2>
<p>最後に、ニューラルネットについて紹介します。 ニューラルネットの話になるとしばしば右図のようなグラフを見るのですが（<a href="https://stats.stackexchange.com/questions/366707/a-logistic-regression-with-neural-network-mindset-vs-a-shallow-neural-network">Stack Overflowのとあるページ</a>より）、これが何かを理解するために左図のロジットに戻ってみます。</p>
<figure>
<img src="https://i.stack.imgur.com/fKvva.png" alt="ニューラルネット" /><figcaption>ニューラルネット</figcaption>
</figure>
<p>左図のお気持ちとしては特徴量<code>input</code>をたくさん入れて（<code>+1</code>は切片のことです）、目的変数がとあるクラスに入る確率を求めているということです。 右図では、入力層<code>Layer L1</code>と出力層<code>Layer L3</code>の間に中間層<code>Layer L2</code>が入っています。 つまり、特徴量をそのまま分類器に突っ込むのではなく、中間層でゴニョゴニョしてから分類機に入れているのです。</p>
<ul>
<li>例えば交差項を入れる、多項式を入れるというのもゴニョゴニョの一種と考えることができます。</li>
</ul>
<p>ニューラルネットも<code>caret</code>で簡単に実装できます。</p>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
vote_nnet &lt;- train(
  target ~ .,
  data = data_vote,
  method = &quot;nnet&quot;,
  preProcess = c(&quot;center&quot;, &quot;scale&quot;),
  trace = FALSE
)

confusionMatrix(predict(vote_nnet, data_vote), data_vote$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   0   1
         0 230 127
         1 159 947
                                          
               Accuracy : 0.8045          
                 95% CI : (0.7832, 0.8245)
    No Information Rate : 0.7341          
    P-Value [Acc &gt; NIR] : 1.938e-10       
                                          
                  Kappa : 0.4858          
                                          
 Mcnemar&#39;s Test P-Value : 0.06679         
                                          
            Sensitivity : 0.5913          
            Specificity : 0.8818          
         Pos Pred Value : 0.6443          
         Neg Pred Value : 0.8562          
             Prevalence : 0.2659          
         Detection Rate : 0.1572          
   Detection Prevalence : 0.2440          
      Balanced Accuracy : 0.7365          
                                          
       &#39;Positive&#39; Class : 0               
                                          </code></pre>
</div>
<div class="layout-chunk" data-layout="l-body">
<pre class="r"><code>
party_nnet &lt;- train(
  target ~ .,
  data = data_party,
  method = &quot;nnet&quot;,
  preProcess = c(&quot;center&quot;, &quot;scale&quot;),
  trace = FALSE
)

confusionMatrix(predict(party_nnet, data_party), data_party$target)</code></pre>
<pre><code>
Confusion Matrix and Statistics

          Reference
Prediction   1   2   3   4   5   6   7   8   9  90
        1  328  61  84 110  19  25   3   2   5   8
        2   35 143  85  21   2 100  14  14   0   9
        3    0   0   0   0   0   0   0   0   0   0
        4    0   0   0   0   0   0   0   0   0   0
        5    0   0   0   0   0   0   0   0   0   0
        6    0   0   0   0   0   0   0   0   0   0
        7    0   0   0   0   0   0   0   0   0   0
        8    0   0   0   0   0   0   0   0   0   0
        9    0   0   0   0   0   0   0   0   0   0
        90   0   0   0   0   0   0   0   0   0   0

Overall Statistics
                                         
               Accuracy : 0.441          
                 95% CI : (0.411, 0.4714)
    No Information Rate : 0.3399         
    P-Value [Acc &gt; NIR] : 4.765e-12      
                                         
                  Kappa : 0.2226         
                                         
 Mcnemar&#39;s Test P-Value : NA             

Statistics by Class:

                     Class: 1 Class: 2 Class: 3 Class: 4 Class: 5 Class: 6 Class: 7 Class: 8
Sensitivity            0.9036   0.7010   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Specificity            0.5504   0.6759   1.0000   1.0000  1.00000    1.000  1.00000  1.00000
Pos Pred Value         0.5085   0.3381      NaN      NaN      NaN      NaN      NaN      NaN
Neg Pred Value         0.9173   0.9054   0.8418   0.8773  0.98034    0.883  0.98408  0.98502
Prevalence             0.3399   0.1910   0.1582   0.1227  0.01966    0.117  0.01592  0.01498
Detection Rate         0.3071   0.1339   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Detection Prevalence   0.6039   0.3961   0.0000   0.0000  0.00000    0.000  0.00000  0.00000
Balanced Accuracy      0.7270   0.6885   0.5000   0.5000  0.50000    0.500  0.50000  0.50000
                     Class: 9 Class: 90
Sensitivity          0.000000   0.00000
Specificity          1.000000   1.00000
Pos Pred Value            NaN       NaN
Neg Pred Value       0.995318   0.98408
Prevalence           0.004682   0.01592
Detection Rate       0.000000   0.00000
Detection Prevalence 0.000000   0.00000
Balanced Accuracy    0.500000   0.50000</code></pre>
</div>
<p>SVMと大体同じという感じでした。</p>
<ul>
<li>ちなみに、いわゆるディープラーニングとは、ディープニューラルネット(DNN)と呼ばれるように、中間層を増やしていったニューラルネットになります。</li>
<li>Googleが開発したTensorFlowというディープラーニング用のフレームワークを使いやすくしたkerasというフレームワークをRから実行することができます（<a href="https://tensorflow.rstudio.com/">TensorFlow for R</a>）を参照。</li>
</ul>
<!--radix_placeholder_article_footer-->
<!--/radix_placeholder_article_footer-->
</div>

<div class="d-appendix">
</div>


<!--radix_placeholder_site_after_body-->
<!--/radix_placeholder_site_after_body-->
<!--radix_placeholder_appendices-->
<div class="appendix-bottom"></div>
<!--/radix_placeholder_appendices-->
<!--radix_placeholder_navigation_after_body-->
<!--/radix_placeholder_navigation_after_body-->

</body>

</html>
